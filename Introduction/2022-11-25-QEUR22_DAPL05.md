---
title: QEUR22_DAPL05:　応用編(5)～閑話休題 – Random Forest(by Python)
date: 2022-11-25
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "Random Forest", "異常判別"]
excerpt: JuliaとFluxを使った画像判別
---

## QEUR22_DAPL05:　応用編(5)～閑話休題 – Random Forest(by Python)

## ～　だって・・・、「Boot Strap」が必要なので・・・　～

QEU:FOUNDER （設定65歳） ： “方針変更です。Python言語でのトライアルを延長し、Pythonの下で**Random Forestを使った予測**をしてみましょう。”

D先生 （設定65歳）： “あれ？Random Forestなんか、Julia言語で簡単にできるでしょうに・・・。あっ、紹介を忘れました。この番組は**「高齢者によるイノベーション」**です。”

![imageJL1-73-1](/2022-11-25-QEUR22_DAPL05/imageJL1-73-1.jpg)

QEU:FOUNDER  ： “決定木において、**「学習データにブートストラップを使ったほうが良いかな？」**と・・・。Positiveデータの数が少なすぎるんです。Positive(exoである)データ数は、Negative(exoでない)データ数の100分の1もないでしょう。教師あり学習の場合、少なくとも比率が5分の1ぐらいになるように増やしたい。これは個人的な意見・・・。”

D先生 ： “つまり、Julia言語のプログラムを構築するのは、面倒くさいと・・・(笑)。”

QEU:FOUNDER ： “もちろん！「楽ちん」が一番！それでは、最初にブートストラップのためのプログラムをドン！！予測はデータを生成してからやりましょう。”

```python
#=
#   PYTHONで新しい、プロセス異常検出ロジックをやってみる
#   引用：Exoplanet_Huntingの機械学習
#   TRAIN＿POSITIVESをBOOTSTRAPして、学習データをふやします。
#=
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math

# -----
# << train_positives >>
df_x = pd.read_csv("csv_train_positives_temp.csv")
df_x = df_x.loc[:,"p1":"m10"]
df_x.head()

# -----
# BOOT STRAPPING
mx_mean = []
for i in range(1000):

    # -----
    # 5 - sampling
    arr_index = np.random.choice(len(df_x), 5)
    print("arr_index: ", arr_index)

    df_sample = df_x.loc[arr_index,:]
    #df_sample
    df_mean = df_sample.mean(axis=0)
    print(df_mean.values)

    if i == 0:
        mx_mean = [df_mean.values]
    else:
        mx_mean = np.concatenate([mx_mean, [df_mean.values]], axis = 0)

print(mx_mean)

# -----
# COLUMNS
arrp_column = ["p{}".format(i+1) for i in range(10)]
arrm_column = ["m{}".format(i+1) for i in range(10)]
arr_column = arrp_column + arrm_column
print(arr_column)

# -----
# SAVE CSV FILE
df_out = pd.DataFrame(mx_mean, columns=arr_column)
print(df_out)

df_out.to_csv("csv_train_positives_boot.csv")

```

D先生 ： “これでPositiveデータのみを増やしたんですね。”

QEU:FOUNDER ： “NegativeとTestデータは変えていません。次は、Random Forestのプログラムをドン・・・。”

```python
# ------
# exoplanet hunting(with bootstrap)
# 初期実験
# ------
# import packages
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df_test = pd.read_csv("csv_test_all_combine.csv")
# ------
print("--- negative ---")
df_test.loc[df_test["result"]=="negative", :].describe().T # T transposes the table
# ------
print("--- positive ---")
df_test.loc[df_test["result"]=="positive", :].describe().T # T transposes the table
#df_test.head()
#df_test.info()

# ------
df_train = pd.read_csv("csv_train_all_combine.csv")
df_train.head()

# ------
# 散布図マトリックス
dfcut_test = df_test.loc[:,"m1":"result"]
g_test = sns.pairplot(dfcut_test, hue='result')
g_test.fig.suptitle("Scatterplot and histogram of pairs of variables by result", 
               fontsize = 14, # defining the size of the title
               y=1.05); # y = definig title y position (height)

# ------
# X-Y分離(TRAIN)
df_train['result'] = df_train['result'].replace('negative', 0).replace('positive', 1)
y_train = df_train['result']
X_train = df_train.drop(['NO', 'result'], axis=1)
print("--- y_train ---")
print(y_train)
print("--- X_train ---")
print(X_train)

# ------
# X-Y分離(TEST)
df_test['result'] = df_test['result'].replace('negative', 0).replace('positive', 1)
y_test = df_test['result']
X_test = df_test.drop(['NO', 'result'], axis=1)
print("--- y_test ---")
print(y_test)
print("--- X_test ---")
print(X_test)

# ------
# ランダムフォレスト
from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=12, 
                             max_depth=6,
                             random_state=42)

# Fit RandomForestClassifier
rfc.fit(X_train, y_train)
# Predict the test set labels
y_pred = rfc.predict(X_test)
print(y_pred)

```

![imageJL1-73-2](/2022-11-25-QEUR22_DAPL05/imageJL1-73-2.jpg)

```python
# ------
# Import `tree` module
from sklearn import tree

features = X_test.columns.values # The name of each column
classes = ['0', '1'] # The name of each class

for estimator in rfc.estimators_:
    print(estimator)
    plt.figure(figsize=(12,6))
    tree.plot_tree(estimator,
                   feature_names=features,
                   class_names=classes,
                   fontsize=8, 
                   filled=True, 
                   rounded=True)
    plt.show()

```

![imageJL1-73-3](/2022-11-25-QEUR22_DAPL05/imageJL1-73-3.jpg)

```python
# ------
# パフォーマンス評価
from sklearn.metrics import classification_report, confusion_matrix

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d').set_title('Maternal risks confusion matrix (0 = negative, 1 = positive)')

print(classification_report(y_test,y_pred))

```

![imageJL1-73-4](/2022-11-25-QEUR22_DAPL05/imageJL1-73-4.jpg)

QEU:FOUNDER ： “Dセンセ・・・。パフォーマンスはどう？”

D先生 ： “数字はよさげですが、ダメダメです。**Testデータセットには５つしかPositiveデータがありません。そのうち、４つを見逃しているんだから・・・。**”

QEU:FOUNDER ： “じゃあ、このリベンジをどうする？”

```python
df_test = pd.read_csv("csv_test_all_combine.csv")

# ------
# コラム８以上をまとめる
df_test["p6"] = df_test["p6"] + df_test["p7"] + df_test["p8"] + df_test["p9"] + df_test["p10"]
df_test["m8"] = df_test["m8"] + df_test["m9"] + df_test["m10"]
del df_test["p7"]
del df_test["p8"]
del df_test["p9"]
del df_test["p10"]
del df_test["m9"]
del df_test["m10"]
df_test

# ------
df_train = pd.read_csv("csv_train_all_combine.csv")

# ------
# コラム８以上をまとめる
df_train["p6"] = df_train["p6"] + df_train["p7"] + df_train["p8"] + df_train["p9"] + df_train["p10"]
df_train["m8"] = df_train["m8"] + df_train["m9"] + df_train["m10"]
del df_train["p7"]
del df_train["p8"]
del df_train["p9"]
del df_train["p10"]
del df_train["m9"]
del df_train["m10"]
df_train

```

D先生 ： “決定木の構造を見ると、m8が最も有意なメトリックスになっています。いっそのこと、m8以上をまとめたらどうですか？”

QEU:FOUNDER ： “じゃあ、ついでにp6以上もまとめてしまいましょう・・・。決定木の結果だけをドン！！”

![imageJL1-73-5](/2022-11-25-QEUR22_DAPL05/imageJL1-73-5.jpg)

D先生 ： “妥当な構造になりましたね。”

QEU:FOUNDER ： “じゃあ、D先生のご期待のパフォーマンスをみてみましょう。”

![imageJL1-73-6](/2022-11-25-QEUR22_DAPL05/imageJL1-73-6.jpg)

D先生 ： “おお・・・。なんと、もっと悪くなってしまった。もともとのデータが「アレ」なんで、しょうがないですが・・・。”

QEU:FOUNDER ： “考えてみれば、exoplanetデータって**「超いびつな情報群」**なんだけど、これを処理して正確に判別できるディープラーニングってすごいよね・・・。我々はCUSUMメトリックスで波形の情報を消してしまったのですが、実は波形にクリティカルな情報があったんでしょうね。”

D先生 ： “ただし、波形を使うということはBootStrapみたいな技を使うことができないから・・・。”

QEU:FOUNDER ： “なんども注意していますが、今回はプロセス異常検出の予備実験ですから、これでいいんです。”


## ～　まとめ　～

C部長 : “コレ(↓)・・・、面白いですね。時間限定公開です。”

[![MOVIE1](http://img.youtube.com/vi/-7nHJAHkmF4/0.jpg)](http://www.youtube.com/watch?v=-7nHJAHkmF4 "本間龍氏講演会[五輪狂騒曲〜東京で起きたこと、札幌で起こること] ダイジェスト2022年10月08日【12月11日までの限定配信です】")

QEU:FOUNDER ： “もう、大好物です。”

C部長 : “この先生(↑)は好きですか？”

QEU:FOUNDER ： “そりゃあもう大好きです。とても個性的だからね。名前とルックスもステキです（笑）。”

C部長 : “先生は、**世の中は洗脳でできていることを教えてくれました**。”

