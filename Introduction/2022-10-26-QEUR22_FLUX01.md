---
title: QEUR22_FLUX01:　Gradient_Descent – Pythonの場合
date: 2022-10-26
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "Gradient_Descent", "ディープラーニング"]
excerpt: Pythonを使ったGradient_Descent
---

## QEUR22_FLUX01:　Gradient_Descent – Pythonの場合

## ～　ディープラーニングって、ちょっと・・・・　～

D先生 （設定65歳）： “一旦、基本的な機械学習法は休みましょう。次は**「ディープラーニング(Deep Learning)」**です。おっと・・・、ちなみに、この番組は**「高齢者によるイノベーション」**です。人生の大先輩の皆さま、イノベーションをやってますか？”

![imageJL1-61-1](/2022-10-26-QEUR22_FLUX01/imageJL1-61-1.jpg)

QEU:FOUNDER （設定65歳） ： “こんなセリフ（↑）を軽々といえる実力があるので、イノベーションなんかは**「へ」**じゃ・・・。・・・ったく、最近の若いもんは「イノベーションごとき」もろくにできない。まったくもう・・・。最近は円が安くなって、晩飯が一品減ったじゃないか・・・。若いモンが貧乏になるのは「エンジョイ」だが、ワシが貧乏になるのは「かわいそう」・・・。”

![imageJL1-61-2](/2022-10-26-QEUR22_FLUX01/imageJL1-61-2.jpg)

D先生 ： “あらあら・・・・、大先輩様すいません。最近の若いモンは搾取され、メタメタに迫害されたせいか、なぜか**無能（オッサンの気に入らないタイプ）が多い**ようなんで・・・。私も高齢者の端くれなんだけど、ちょっと若いもんの手伝いさせてもらいます。さて、今回はディープラーニングの第一回です。・・・ということは、最初は**勾配降下法(GD：Gradient Descent)**あたり？”

QEU:FOUNDER ： “そうね・・・。リクエストにお応えしてGDをやりましょ。ついでに、GDがわかれば、小生がディープラーニング(DL)をどう見ているのかがわかります。”

D先生 ： “えっ？FOUNDERは「DL推し」だと思っていました。”

QEU:FOUNDER ： “それは場合によりケリ・・・・、根本思想は動いていないんだけどね・・・。まずは、Pythonプログラムをドン。この資料（↓）を参考にしたよ。・・・というか、Pythonの民主化が進み、**わかりやすい記事が増えた**よね。”

![imageJL1-61-3](/2022-10-26-QEUR22_FLUX01/imageJL1-61-3.jpg)

D先生 ： “もう10年前では考えられない**「夢のような状態」**ですね。しかし・・・、Julia言語がこのレベルにいくのはいつ頃なんだろうなぁ・・・。”

```python
# python Gradient Decent Example
# もっとも基本的なデモプログラム
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn
import random
import math
%matplotlib inline
df=pd.read_csv('Advertising.csv')
#df.head()
X=df[['TV','radio','newspaper']]
Y=df['sales']
Y=np.array((Y-Y.mean())/Y.std())
X=X.apply(lambda rec:(rec-rec.mean())/rec.std(),axis=0)
print(X)

# ----
def initialize(dim):
    b=random.random()
    theta=np.random.rand(dim)
    return b,theta
b,theta=initialize(3)
print("--- initialize ---")
print("Bias: ",b,"Weights: ",theta)

# ----
def predict_Y(b,theta,X):
    return b + np.dot(X,theta)
Y_hat=predict_Y(b,theta,X)
print("--- predict_Y ---")
print(Y_hat[0:5])

# ----
def get_cost(Y,Y_hat):
    Y_resd=Y-Y_hat
    return np.sum(np.dot(Y_resd.T,Y_resd))/len(Y-Y_resd)
Y_hat=predict_Y(b,theta,X)
print("--- get_cost ---")
print(get_cost(Y,Y_hat))

# ----
def update_theta(x,y,y_hat,b_0,theta_o,learning_rate):
    db=(np.sum(y_hat-y)*2)/len(y)
    dw=(np.dot((y_hat-y),x)*2)/len(y)
    b_1=b_0-learning_rate*db
    theta_1=theta_o-learning_rate*dw
    return b_1,theta_1
print("After initialization -Bias: ",b,"theta: ",theta)
Y_hat=predict_Y(b,theta,X)
b,theta=update_theta(X,Y,Y_hat,b,theta,0.01)
print("After first update -Bias: ",b,"theta: ",theta)
print("--- update_theta ---")
print(get_cost(Y,Y_hat))

# ----
def run_gd_history(X,Y,alpha,num_iterations):
    b,theta=initialize(X.shape[1])
    iter_num, result_idx = 0, 0
    gd_iterations_df=pd.DataFrame(columns=['iteration','cost','theta1','theta2','theta3'])
    for each_iter in range(num_iterations):
        Y_hat=predict_Y(b,theta,X)
        this_cost=get_cost(Y,Y_hat)
        prev_b=b
        prev_theta=theta
        b,theta=update_theta(X,Y,Y_hat,prev_b,prev_theta,alpha)
        if(iter_num%20==0):
            gd_iterations_df.loc[result_idx]=[iter_num,this_cost,theta[0],theta[1],theta[2]]
            result_idx=result_idx+1
        iter_num +=1
    print("Final Estimate of b and theta : ",b,theta)
    return gd_iterations_df,b,theta
gd_iterations_df,b,theta=run_gd_history(X,Y,alpha=0.002,num_iterations=200)
print(gd_iterations_df[0:5])

# ----
fig = plt.figure(figsize = (12,6))
alpha_df_1,b,theta=run_gd_history(X,Y,alpha=0.01,num_iterations=2000)
alpha_df_2,b,theta=run_gd_history(X,Y,alpha=0.001,num_iterations=2000)
# ----
ax1 = fig.add_subplot(1,2,1)
ax1.scatter(alpha_df_1['theta1'],alpha_df_1['cost'],label='theta1')
ax1.scatter(alpha_df_1['theta2'],alpha_df_1['cost'],label='theta2')
ax1.scatter(alpha_df_1['theta3'],alpha_df_1['cost'],label='theta3')
ax1.legend(loc='best', fontsize=14)
ax1.set_ylabel('cost')
ax1.set_xlabel('Theta(1,2,3)')
ax1.set_title('Transition of coefficient : value of Thetas')
# ----
ax2 = fig.add_subplot(1,2,2)
ax2.plot(alpha_df_1['iteration'],alpha_df_1['cost'],label="alpha=0.01")
ax2.plot(alpha_df_2['iteration'],alpha_df_2['cost'],label="alpha=0.001")
ax2.legend(loc='best', fontsize=14)
ax2.set_ylabel('cost')
ax2.set_xlabel('Number of iterations')
ax2.set_title('Cost Vs. Iterations for different alpha values')
# -----
fig.tight_layout()
plt.show()

```

QEU:FOUNDER ： “まずは、使用するデータセットの説明から・・・。このデータは説明変数（X）が3件だけの、「我々の例題にふさわしい簡単なシロモノ」です。”

![imageJL1-61-4](/2022-10-26-QEUR22_FLUX01/imageJL1-61-4.jpg)

D先生 ： “こんなモン・・・。重回帰分析すれば、すぐに終わるのに・・・(笑)。”

QEU:FOUNDER ： “それではイカん・・・。恐れ多くも、このロジックはディープラーニングでは**「オプティマイザ(optimizer)」と呼ばれる基幹システムのプロトタイプ**ですからね。ともあれ、能書きはいいので、プログラムを実行してみましょう。”

![imageJL1-61-5](/2022-10-26-QEUR22_FLUX01/imageJL1-61-5.jpg)

D先生 ： “おっ・・・。**「θ(Theta)」**とな・・・？”

QEU:FOUNDER ： “重回帰分析における一次係数と考えてください。右のグラフによると初期値は乱数で設定されるのですが、**最後には妥当な値に収束する**んです。後は、左側のグラフは繰り返し数とコストと関係があります。このグラフには見覚えあるでしょ？”

D先生 ： “（この手のグラフは）**強化学習で何回も見たことがあります**（笑）。”

![imageJL1-61-6](/2022-10-26-QEUR22_FLUX01/imageJL1-61-6.jpg)

QEU:FOUNDER ： “強化学習には本当に時間がかかる・・・。困っちゃうよねぇ・・・。こんなに時間がかかるのはなぜ？そんなにインプット情報が必要なの？それともディープラーニングのせい？”

D先生 ： “Gradient Descentを見せつけられた流れからみると、「ディープラーニングのせい」とプレッシャーがかかっていそうで・・・（笑）。”

QEU:FOUNDER ： “まあ・・・。小生としては、「ここらへん」に興味があるわけです。”


## ～　まとめ　～

QEU:FOUNDER ： “最近のお金の動きは面白いねぇ・・・。”

![imageJL1-61-7](/2022-10-26-QEUR22_FLUX01/imageJL1-61-7.jpg)

C部長 : “なんか・・・、昔とは様子が違いますね。”

![imageJL1-61-8](/2022-10-26-QEUR22_FLUX01/imageJL1-61-8.jpg)

C部長 : “円が安いの？それともダラーが高いの？”

QEU:FOUNDER ： “知らない・・・（笑）。”


