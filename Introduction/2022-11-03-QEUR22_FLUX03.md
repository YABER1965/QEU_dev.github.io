---
title: QEUR22_FLUX03:　ディープラーニング(1)～分類-Pythonの場合
date: 2022-11-03
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "Keras", "ディープラーニング", "分類"]
excerpt: PythonとKerasを使った分類
---

## QEUR22_FLUX03:　ディープラーニング(1)～分類-Pythonの場合

## ～　DLはすでに「常識」レベル　～

D先生 （設定65歳）： “いきなりですが、この番組は**「高齢者によるイノベーション」**です。さあ、AIを始めましょう。みんな大好き、「AI」から・・・。”

![imageJL1-63-1](/2022-11-03-QEUR22_FLUX03/imageJL1-63-1.jpg)

QEU:FOUNDER （設定65歳） ： “まあ・・・、ディープラーニングは脳の構造からヒントを得ているので、**「人工知能(AI)」**になるのかなぁ・・・。でも、ディープラーニングは常識になると思うよ。少なくとも、近い将来に・・・。”

D先生 ： “**他の機械学習の手法より「簡単」ですからね、意外なことに・・・。**”

![imageJL1-63-2](/2022-11-03-QEUR22_FLUX03/imageJL1-63-2.jpg)

QEU:FOUNDER ： “他の手法は**データの性質から派生した数理モデル**を前提していますからね。ディープラーニングは、その点は若干ゆるいですからね。・・・もういいでしょ、能書きは・・・。いままでさんざんディープラニングの例題をやっていたんだが、今回はJulia言語との比較のためにもう一度やります。”

![imageJL1-63-3](/2022-11-03-QEUR22_FLUX03/imageJL1-63-3.jpg)

D先生 ： “私たちのQEUプロプロジェクトでは、分析として「分類」を使うことはありませんが、あえてコレ（↑）からはじめるんですね。”

QEU:FOUNDER ： “回帰の例題はつぎにやります。それではプログラムをドン・・・。今回は実行結果を混ぜています。”

```python
# Python - DeepLearning with Keras
# Breast Cancer - Deep Learning
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data = pd.read_csv("breast-cancer-wisconsin-data.csv")
data.head()

```

![imageJL1-63-4](/2022-11-03-QEUR22_FLUX03/imageJL1-63-4.jpg)

```python
# ----
data.drop(['id','Unnamed: 32'],axis=1,inplace=True)
data.head()

```

![imageJL1-63-5](/2022-11-03-QEUR22_FLUX03/imageJL1-63-5.jpg)

```python
# ----
from sklearn.preprocessing import LabelEncoder
lb=LabelEncoder()
data['diagnosis']=lb.fit_transform(data['diagnosis'])
data['diagnosis'].value_counts()
data

# ----
# CSVファイルの出力
data.to_csv('breast-cancer-processed-data.csv')

```

![imageJL1-63-6](/2022-11-03-QEUR22_FLUX03/imageJL1-63-6.jpg)

```python
# ----
# Data Splitting
X=data.drop('diagnosis',axis=1)
y=data['diagnosis']

# ----
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=42)
X_train

```

![imageJL1-63-7](/2022-11-03-QEUR22_FLUX03/imageJL1-63-7.jpg)

```python
# ----
# Standardizing the data
from sklearn.preprocessing import StandardScaler
std=StandardScaler()
X= std.fit(X).transform(X)
X_trainstd=std.fit_transform(X_train)
X_teststd=std.transform(X_test)
X_trainstd

```

![imageJL1-63-8](/2022-11-03-QEUR22_FLUX03/imageJL1-63-8.jpg)

```python
# ----
# Creating the Neural Network
import tensorflow as tf
tf.random.set_seed(42)
from tensorflow import keras

model = keras.Sequential([
                          keras.layers.Flatten(input_shape=(30,)),
                          keras.layers.Dense(20,activation='relu'),
                          keras.layers.Dense(2,activation= 'sigmoid')
])

model.compile(optimizer="adam",
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history=model.fit(X_trainstd,y_train,validation_split=0.2,epochs=20)

```

![imageJL1-63-9](/2022-11-03-QEUR22_FLUX03/imageJL1-63-9.jpg)

```python
# ----
# Visualizing training accuracy and validation accuracy
# plot the training and validation accuracy and loss at each epochs:
fig = plt.figure(figsize = (12,6))
# ----
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1,len(loss)+1)
# ----
ax1 = fig.add_subplot(1,2,1)
ax1.plot(epochs,loss,'y',label = 'Training loss')
ax1.plot(epochs,val_loss,'r',label = 'Validation loss')
ax1.set_title('TechVidvan Training and Validation loss')
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Loss')
ax1.legend(loc='best', fontsize=14)
# ----
ax2 = fig.add_subplot(1,2,2)
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
# ----
ax2.plot(epochs,acc,'y',label = 'Training acc')
ax2.plot(epochs,val_acc,'r',label = 'Validation acc')
ax2.set_title('TechVidvan Training and Validation accuracy')
ax2.set_xlabel('Epochs')
ax2.set_ylabel('Accuracy')
ax2.legend(loc='best', fontsize=14)
# ----
fig.tight_layout()
plt.show()

```

![imageJL1-63-10](/2022-11-03-QEUR22_FLUX03/imageJL1-63-10.jpg)

```python
# ----
# Making a predictive system(Probability)
y.pred=model.predict(X_teststd)
print(y.pred.shape)
print(y.pred)

```

![imageJL1-63-11](/2022-11-03-QEUR22_FLUX03/imageJL1-63-11.jpg)

```python
# ----
# prediction via Probability
y.pred_labels=[np.argmax(i) for i in y.pred]
print(y.pred_labels)

```

![imageJL1-63-12](/2022-11-03-QEUR22_FLUX03/imageJL1-63-12.jpg)

```python
# ----
# importing the accuracy measuring function
from sklearn.metrics import accuracy_score
 
# evaluating the accuracy
print(accuracy_score(y_test, y.pred_labels))
#0.9787234042553191

# ----
# importing the accuracy measuring function
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Drawing matrix
cm = confusion_matrix(y_test, y.pred_labels)
sns.heatmap(cm, annot = True)

```

![imageJL1-63-13](/2022-11-03-QEUR22_FLUX03/imageJL1-63-13.jpg)

D先生 ： “典型的な機械学習の実務の流れですね。成熟したPythonの場合、Webには類似の例題が多すぎて、特にコメントすることがないくらい・・・（笑）。”

QEU:FOUNDER ： “Julia言語には、現在のところ（例題が）少ないんだよ・・・（泣）。”

D先生 ： “じゃあ、次は**Julia言語で・・・。**”


## ～　まとめ　～

QEU:FOUNDER ： “さすが**オッサンのアイドル**はすごいこというね！！”

[![MOVIE1](http://img.youtube.com/vi/g9KkNQ_jpXc/0.jpg)](http://www.youtube.com/watch?v=g9KkNQ_jpXc "竹中平蔵の統一教会擁護は何故起きるのか？日本一と言ってもいいくらい嫌われている竹中平蔵さんはなぜカルトを擁護するのか？安冨歩東大教授。一月万冊")

C部長 : “なんで、こんな思考になるの？”

![imageJL1-63-14](/2022-11-03-QEUR22_FLUX03/imageJL1-63-14.jpg)

QEU:FOUNDER ： “**法で善悪の決定をするんだ。愚民は主観でガタガタいうな！**このオッサン（↑）は、大衆はテレビだけの情報をうのみにして知識の幅が狭いので、ごまかせると思っているんです。そういう意味では、さすが**エース**ですね！”

C部長 : “あの団体、本当のところはどうなんでしょう・・・。”

![imageJL1-63-15](/2022-11-03-QEUR22_FLUX03/imageJL1-63-15.jpg)

QEU:FOUNDER ： “小生もしらんよ・・・。でも、A国の記事は参考になります。例えば、**「看板儀式」**の由来は知ってた？”

C部長 : “えーっつ！？これが、**「家庭」**の由来！？”

![imageJL1-63-16](/2022-11-03-QEUR22_FLUX03/imageJL1-63-16.jpg)

QEU:FOUNDER ： “さらにコレ（↓）・・・。”

![imageJL1-63-17](/2022-11-03-QEUR22_FLUX03/imageJL1-63-17.jpg)

C部長 : “あの儀式と教義との整合性がとれていますね。”

QEU:FOUNDER ： “**個人の否定（堕落）・・・。一般概念としての家庭の否定（堕落）・・・。**こういうことを理解したうえで議論しないと・・・。”

