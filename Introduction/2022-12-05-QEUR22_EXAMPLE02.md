---
title: QEUR22_EXAMPLE02:　事例(2)～ 手書き数字の判別-Python-Flux(素うどん)
date: 2022-12-05
tags: ["QEUシステム", "メトリックス", "Julia言語", "機械学習", "PCA", "ディープラーニング", "画像判別"]
excerpt: JuliaとFluxを使った画像判別
---

## QEUR22_EXAMPLE02:　事例(2)～ 手書き数字の判別-Python-Flux(素うどん)

## ～　今回は「素うどん」・・・　～

QEU:FOUNDER （設定65歳） ： “今回は、ひきつづいてJuliaですが、これをやりましょう。ドン！！”

![imageJL1-81-1](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-1.jpg)

D先生 （設定65歳）： “・・・と、いうことは、**純FLUX**ですか・・・。この番組は**「高齢者によるイノベーション」**です。”

![imageJL1-81-2](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-2.jpg)

QEU:FOUNDER  ： “今回も手書き数字(MNIST)をJulia言語でやってみる趣向です。今回は、Fluxの総本山のコンテンツを先生としました。それでも、結果として、コードがかなり変わりましたが・・・。”

D先生 ： “う～ん・・・、コードを改造する必要はないでしょうに・・・。”

QEU:FOUNDER ： “「素うどん」とはいっても、このサイトのコードには**「ネギ」**ものっていなかった。それに**「かまぼこ」**も・・・（笑）。それも踏まえて、コードのボリュームはちょっとだけ大きくなっています。”

```julia
# Flux-MNIST(素うどんモデル)
# Simple Multi-layer Perceptron
using Flux, Statistics
using Flux.Data: DataLoader
using Flux: onehotbatch, onecold, logitcrossentropy, throttle, @epochs, params
using Base.Iterators: repeated
using CUDA
using MLDatasets
if has_cuda()        # Check if CUDA is available
    @info "CUDA is on"
    CUDA.allowscalar(false)
end

# ------
# パラメータ群
rate::Float64 = 1e-3    # learning rate
batchsize::Int = 2048   # batch size
epochs::Int = 10        # number of epochs
device::Function = gpu  # set as gpu, if gpu available

# ------
function getdata()

    ENV["DATADEPS_ALWAYS_ACCEPT"] = "true"

    # Loading Dataset    
    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)
    xtest, ytest = MLDatasets.MNIST.testdata(Float32)
	
    # Reshape Data in order to flatten each image into a linear array
    xtrain = Flux.flatten(xtrain)
    xtest = Flux.flatten(xtest)

    # One-hot-encode the labels
    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)

    # Batching
    train_data = DataLoader((xtrain, ytrain), batchsize=batchsize, shuffle=true)
    test_data = DataLoader((xtest, ytest), batchsize=batchsize)

    return train_data, test_data
end

# ------
function build_model()
    return Chain(
         Dense(784, 48, relu),
            Dense(48, 10))
end

# ------
function loss_all(dataloader, model)
    l = 0f0
    for (x,y) in dataloader
        l += logitcrossentropy(model(x), y)
    end
    l/length(dataloader)
end

# ------
function accuracy(data_loader, model)
    acc = 0
    for (x,y) in data_loader
        acc += sum(onecold(cpu(model(x))) .== onecold(cpu(y)))*1 / size(x,2)
    end
    acc/length(data_loader)
end

# ------
# MAIN ROUTINE
# ------
# Load Data
train_data,test_data,Xtest_data,ytest_data = getdata()

# ------
train_losses = []
test_losses  = []
train_acces  = []
test_acces   = []

# ------
# Construct model
m = build_model()
train_data = device.(train_data)
test_data = device.(test_data)
m = device(m)
loss(x,y) = logitcrossentropy(m(x), y)

## Training
callbacks = [
    () -> @show(loss_all(train_data, m))
    () -> push!(train_losses, loss_all(train_data, m))
    () -> push!(test_losses, loss_all(test_data, m))
    () -> push!(train_acces, accuracy(train_data, m))
    () -> push!(test_acces, accuracy(test_data, m))
]

opt = ADAM(rate)
# ------
@epochs epochs Flux.train!(loss, params(m), train_data, opt, cb = callbacks)

```

![imageJL1-81-3](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-3.jpg)

```julia
# ------
# Display the results
using Plots

# ------
# Losses
x = range(1, length(train_losses))
plot(x, [train_losses,test_losses], title="Learning Curve - Loss trend", label=["Train" "Test"], linewidth=3)

```

![imageJL1-81-4](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-4.jpg)

```julia
# ------
# Accuracy
plot(x, [train_acces,test_acces], title="Learning Curve - Accuracy trend", label=["Train" "Test"], lin-ewidth=3)
println("train_acces[end]:", train_acces[end])
println("test_acces[end]:", test_acces[end])

```

![imageJL1-81-5](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-5.jpg)

```julia
# ------
# Confusion Matrix
cm = zeros(Int64, 10, 10)

for (x,y) in test_data
    pred_test_labels = onecold(cpu(m(x)))
    true_test_labels = onecold(cpu(y))
    #println("pred_test_labels:", pred_test_labels)
    #println("true_test_labels:", true_test_labels)
	# ---
	for i in 1:length(pred_test_labels)
		cm[pred_test_labels[i],true_test_labels[i]] += 1
	end
end

# ------
# Display raw data
cm

```

![imageJL1-81-6](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-6.jpg)

```julia
# ------
# Display Heatmap
heatmap(cm, c=:dense, title="Confusion Matrix, accuracy = "*string(test_acces[end]), ylabel="True label", xlabel= "Predicted label")

```

![imageJL1-81-7](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-7.jpg)

D先生 ： “**ミニバッチ**の考え方を取り入れていますよね。”

QEU:FOUNDER ： “学習データ数が大きいから、過学習を防止するのに採用したんでしょうね。。”

D先生 ： “Confusion Matrixとヒートマップが見にくいです。”

QEU:FOUNDER ： “じゃあ、ヒートマップを消してください。あまり意味がないと思うんで・・・。”

D先生 ： “投げやりだなぁ・・・。”

QEU:FOUNDER ： “そもそも、やりたかったことはメトリックスの導入です。まずは最初にPCAを導入し、その次にSOART法を使いましょう。”


## ～　まとめ　～

### ・・・　前回の続きです　・・・

C部長 : “Ｊ国では「安いモノしか作れない」ので、人がバタバタ倒れても人々は止まれない。その一方で、**高いモノを作れるＡ国では新しい時代に動き出して**います・・・。”

![imageJL1-81-8](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-8.jpg)

C部長 : “一体、「どんな時代」なんでしょうね？”

![imageJL1-81-9](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-9.jpg)

QEU:FOUNDER ： “教育の場合にはリモートの効果が出てき始めているらしいよ・・・。”
　
![imageJL1-81-10](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-10.jpg)

QEU:FOUNDER ： “リモート学習の効果・・・。結構、すごいと思わない？”

C部長 : “リモート学習の他には？”

[![MOVIE1](http://img.youtube.com/vi/j2TbvmXN_Y4/0.jpg)](https://www.youtube.com/watch?v=j2TbvmXN_Y4 "【落合陽一のシンギュラリティ論】シンギュラリティは2025年に来る／ディフュージョンモデルの衝撃／知的ホワイトカラーが没落する／最新版デジタルネイチャー／音楽と論文が数秒でできる")

QEU:FOUNDER ： “いやいや・・・、**シン某が、2025年には来る**んですよ・・・。ホワイトカラーは大ダメージを受けるんでしょうね。労働から見た人間の価値って、肉体労働の方が高いんだよね。”
　
![imageJL1-81-11](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-11.jpg)

C部長 : “だから、アメリカは、今、大きく動いています。仕事の定義が変わってくるんでしょうね。”

QEU:FOUNDER ： “J国はどうなるんだろうね。２０２５年って・・・。”

C部長 : “**モラハラ全開で変化を阻害し、あいかわらず**なんじゃないんでしょうかね。”
　
![imageJL1-81-12](/2022-12-05-QEUR22_EXAMPLE02/imageJL1-81-12.jpg)

QEU:FOUNDER ： “モタモタしていると、「肉体を輸出する」ようになるんでしょう・・・。”
