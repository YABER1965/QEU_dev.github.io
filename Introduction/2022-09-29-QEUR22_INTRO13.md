---
title: QEUR22_INTRO13:　Julia事例(7) ～決定木(Julia)
date: 2022-09-29
tags: ["QEUシステム", "Julia言語", "機械学習", "決定木"]
excerpt: Julia言語を使った決定木
---

## QEUR22_INTRO13:　Julia事例(7) ～決定木

## ～　精度は高いわけではないが、コレは「汎用的だ」ネ・・・　～

D先生 （設定65歳）： “毎度お騒がせしております**「高齢者によるJulia入門」**の時間です・・・。**「高齢者によるイノベーション」がモットー**でございます。こんな感じ（↓）で社会が沈滞し、混乱するのを避けるために・・・。”

[![MOVIE1](http://img.youtube.com/vi/F8zlVl4V8p0/0.jpg)](http://www.youtube.com/watch?v=F8zlVl4V8p0 "安倍晋三国葬後に火あぶりにされる自己責任論者達。橋下徹と竹中平蔵等で有名になった自己責任論。彼らの待つ未来は悲惨。自己責任論のルーツを辿る。安冨歩東大教授。一月万冊")

D先生： “**昔、無茶苦茶やったことの反動**が来たんですよね・・・。”

QEU:FOUNDER （設定65歳） ： “先生のお言葉には主語がありません。”

D先生（設定65歳）： “例えば、**「A級」**の人とか・・・。”

![imageJL1-14-1](/2022-09-29-QEUR22_INTRO13/imageJL1-14-1.jpg)

QEU:FOUNDER ： “コレ（↑）って、BBSのスクリーン・ショットなので信ぴょう性はどうかなあ・・・。受け手が、「自己責任」で判断してくれることを希望します。”

(T)中　結局はポピュリズムですよね。道を率いるべき人が「何か困ったことがあったら助けてあげるよ」というのは本当のリーダーではありません。「こうしなきゃいけない。みんながんばれ。私たちはこういう方向を目指そう！」と、一人ひとりを喚起すべきなのです。

ギリシャや日本から分かるように、私たちは社会不安とポピュリズムとの悪循環の中にどっぷりはまっています。経済が悪化しているから社会不安が出る。格差が生まれると「可哀想だから助けてあげよう」というポピュリズムの考えが政策にある。
そんなことをしても財政赤字が膨らむ一方です。この悪循環が世界中で起きているのが現状です。
これを断ち切るためには、厳しいことも言えるリーダーが出てくることが一つの条件でしょう。

**大阪市長で日本維新の会代表の橋下さんに期待が集まっている**のも理解できます。もう一つは企業家が成功事例を作ることだと思います。ですから{K}笹さんも今後どんどん成功事例を作って「みんな俺みたいになってみろ」と言ってくれると心強いですね。

{K}笹　私は日本の国民にもっと主体的、自立的であってもらいたい。やはり今までどちらかというと国や行政にもたれかかってきました。
それはある意味では良さでもあったかもしれませんが、もっと一人ひとりが自立していって欲しいし、
若いときから自己責任、自己選択をできるようになって欲しい。この意識が希薄すぎるなと思います。そこの重要性を伝えていきたいですね。

(T)中　今のお話に尽きると思います。**サミュエル・スマイルズの『自助論』という本**が、明治時代によく読まれたそうです。
小泉さんが一番好きな本のひとつがこの『自助論』で、私もゼミの学生には最初にこの自助論を経済学よりも前に読んでもらっています。

「天は自ら助くる者を助く」。自助・自立が出来る者が多ければ多いほど、本当の意味で助けを必要としている人を助けることが出来る。今、船に乗っているとして、その船が沈んだら、自分で泳げる人は泳がないといけない。そうすることによって初めて救命ボートにお年寄りや子供を乗せられる。
みんなが全員救命ボートに乗ろうとしたら全員死んでしまう。厳しいけれどもこれが社会の現実です。これはやはり自助なのです。モチベーションの最終点はこの自助、自立ではないでしょうか。

QEU:FOUNDER  ： “**「厳しいことも言えるリーダー」**・・・。”

[![MOVIE2](http://img.youtube.com/vi/_NS3IxrA8Co/0.jpg)](http://www.youtube.com/watch?v=_NS3IxrA8Co "橋下知事 容赦ない討論　女子高生を泣かせた")

D先生 ： “我々、QEUシステムとしては、自助よりも**「イノベーションが必要である」**という着眼点なんですね。そうすると皆がより幸せになります。”

![imageJL1-14-2](/2022-09-29-QEUR22_INTRO13/imageJL1-14-2.jpg)

QEU:FOUNDER ： “高齢者は**どんどん年金をもらうべき**なんだ・・・・。こんなつまらんドーカツ（↑）で腰砕けにならずに・・・。働く高齢者は多くなったが、働く必要はない。そのかわりに今までの経験と知識を使って、イノベーションをやる。**上記の文章の若者と高齢者を反対にしたら、世の中がうまく回るようになります。**”

D先生 ： “そのための「（高齢者による）Julia入門」です。それでは、本題にいきましょう。今回はディープラーニング・・・？”

QEU:FOUNDER ： “いや・・・。決定木をやります。たまたま見つけたんで・・・。決定木は予測精度こそ「いまいち」だが、とても汎用的な分類器ですよね。とくに新しいことはないので、プログラムをいきましょう。ドン・・・。”

```julia
#=
  決定木による予測(JULIA入門)
=#
using Random
using DecisionTree

# Separate Fisher's Iris dataset features and labels
features, labels = load_data("iris")    # also see "adult" and "digits" datasets

# the data loaded are of type Array{Any}
# cast them to concrete types for better performance
features = float.(features)
labels   = string.(labels)

# -----
# Split database as train and test
function partitionTrainTest(X, y, at = 0.7)
    n = size(X, 1)
    idx = shuffle(1:n)
    train_idx = view(idx, 1:floor(Int, at*n))
    test_idx = view(idx, (floor(Int, at*n)+1):n)
    return X[train_idx,:], X[test_idx,:], y[train_idx], y[test_idx]
end

xtrain,xtest,ytrain,ytest = partitionTrainTest(features, labels, 0.7) # 70% train-30% test
xtrain

# -----
# Pruned Tree Classifier
# train depth-truncated classifier
model = DecisionTreeClassifier(max_depth=2)
fit!(model, xtrain, ytrain)
# pretty print of the tree, to a depth of 5 nodes (optional)
print_tree(model, 5)

# -----
# 単発での予測
# apply learned model(single)
predict(model, [5.9,3.0,5.1,1.9])

# get the probability of each label
predict_proba(model, [5.9,3.0,5.1,1.9])

# -----
# test_Databaseでの予測
# apply learned model(multiple)
ypred = predict(model, xtest)

# -----
# confusion matrix の準備
dim = 3
n   = length(ytest)
ypred_num = []
ytest_num = []
for i in 1:length(ytest)
	if occursin("setosa",ypred[i])
		push!(ypred_num, 1)
	end
	if occursin("versicolor",ypred[i])
		push!(ypred_num, 2)
	end	
	if occursin("virginica",ypred[i])
		push!(ypred_num, 3)
	end	
	# -----
	if occursin("setosa",ytest[i])
		push!(ytest_num, 1)
	end
	if occursin("versicolor",ytest[i])
		push!(ytest_num, 2)
	end	
	if occursin("virginica",ytest[i])
		push!(ytest_num, 3)
	end	
end

# -----
# confusion matrix calculation in Julia
function confusionmatrix(predictions, labels, dim)
   c = zeros(dim, dim)
   for i in 1:length(labels)
       c[labels[i] ,predictions[i]] += 1 
   end 
   return c
end

c = confusionmatrix(ypred_num, ytest_num, dim)
display(c)

```

QEU:FOUNDER ： “例によって、すこしずつ見てみましょうか・・・。決定木の構造の指定から・・・。”

![imageJL1-14-3](/2022-09-29-QEUR22_INTRO13/imageJL1-14-3.jpg)

D先生 ： “深さをきめているんですね。図もわかりやすくって、好きです。”

![imageJL1-14-4](/2022-09-29-QEUR22_INTRO13/imageJL1-14-4.jpg)

QEU:FOUNDER ： “コレ（↑）なんか、便利でしょ？”

D先生 ： “各候補の確率がわかるんですね。これは、いろいろな部分に応用ができます。ベクトルサポートマシンよりもいいかも・・・。”

QEU:FOUNDER ： “外観検査自動機において、**「過検出気味」にチューニングするのが楽になる**よね。次は、confusion_matrixを見てパフォーマンス評価しましょうか・・・。”

![imageJL1-14-5](/2022-09-29-QEUR22_INTRO13/imageJL1-14-5.jpg)

D先生 ： “あれ？またもや自分で作っちゃいましたね・・・（笑）。”

QEU:FOUNDER ： “あるはずなんだが、見つからない。だから自分で作る。簡単なコードだからね。いままで、外観検査自動機はサポートベクトルマシンで総合判定をやっていました。決定木はいかがですか？”

D先生 ： “候補として、悪くはないですね・・・。”


## ～　まとめ　～

QEU:FOUNDER ： “ほう・・・。「あの人」って、A国にいるんですね。確かに、彼の仕事には便利です。”

[![MOVIE1](http://img.youtube.com/vi/VAWwqv_yCQ4/0.jpg)](http://www.youtube.com/watch?v=VAWwqv_yCQ4 "【国葬】国葬によって可視化された「安倍政権」を博士と町山が語る【旧統一教会】覚悟を決めた報道番組とスポンサーの影響力【報道】日米ファクトチェックの違い")

C部長 : “メディアには、彼らなりの事情があるんですね・・・。”

![imageJL1-14-6](/2022-09-29-QEUR22_INTRO13/imageJL1-14-6.jpg)

QEU:FOUNDER ： “この2人は結構、最強・・・。こういうことがが「可視化」されてよかった・・・。”

C部長 : “ともあれ、**「博士」は公約を果たしております。**”
