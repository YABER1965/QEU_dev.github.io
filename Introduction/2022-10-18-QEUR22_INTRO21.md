---
title: QEUR22_INTRO21:　Julia事例(10)～ロジスティック回帰
date: 2022-10-18
tags: ["QEUシステム", "メトリックス", "Julia言語", "ロジスティック回帰"]
excerpt: Julia言語によるロジスティック回帰
---

## QEUR22_INTRO21:　Julia事例(10)～ロジスティック回帰

## ～　これは「好き嫌いがある手法」だが・・・　～

D先生 （設定65歳）： “この番組は、**「高齢者によるJulia言語入門」**でございます。現在、小さな事例を積み上げております。おっと・・・、高齢者がちゃんとイノベーションの旗振りをしないと、このように（↓）通貨がどんどん安くなっていきますよ。何度もいいますが・・・。でも、FOUNDER・・・、高齢者じゃないとダメ？”

![imageJL1-22-1](/2022-10-18-QEUR22_INTRO21/imageJL1-22-1.jpg)

QEU:FOUNDER （設定65歳） ： “この国は**高齢者の方が能力と元気がある**から・・・。むかし、こういう話を聞きました。昔、こんな偉そうなことを言っていたんだ。彼らは「いざという時」にはやってくれますよ。”

![imageJL1-22-2](/2022-10-18-QEUR22_INTRO21/imageJL1-22-2.jpg)

D先生 ： “それはそうですね。若者は平成30年、不断にぶちのめされて、すでに何もできません・・・。”

- **おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」**
- **オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」**
- **オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」**

QEU:FOUNDER ： “ただし、**オッサンにおかれましては、「使い古されたマントラを若い人に押し付ける」のはやめてください。無駄です。**もう一度言うけど、無駄です。そもそも、そんな**「一つ覚え」**のやりすぎで円が安くなったんだから・・・。さて、今回はロジスティック回帰です。コレって、名前は恰好いいんだけどね・・・。”

![imageJL1-22-3](/2022-10-18-QEUR22_INTRO21/imageJL1-22-3.jpg)

D先生 ： “予測精度は、そんなに上がらないですよね。基本は0 or 1の予測ですから、「中間(0.3, 0.5 etc…)」がないんです。”

QEU:FOUNDER ： “ちゃんと予測が成立するには、0群と1群のデータのバランスが取れていないといけません。我々は基本的に、製造プロセスへの適応を考えているので、そんなに不良は発生しないって・・・。・・・なにはともあれやってみましょう。プログラムをドン！まずはPythonから！！！”

```python
# Import packages
import pandas as pd
import numpy as np
data = pd.read_csv("bank-loan.csv") # dataset
data

loan = data[data["default"]>=0]
loan

# Split Database
from sklearn.model_selection import train_test_split 

X = loan.drop(['default'],axis=1) 
Y = loan['default'].astype(str)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.20, random_state=0)
Y_test

# Calculate Metrics
def err_metric(CM): 
     
    TN = CM.iloc[0,0]
    FN = CM.iloc[1,0]
    TP = CM.iloc[1,1]
    FP = CM.iloc[0,1]
    precision =(TP)/(TP+FP)
    accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
    recall_score  =(TP)/(TP+FN)
    specificity_value =(TN)/(TN + FP)
     
    False_positive_rate =(FP)/(FP+TN)
    False_negative_rate =(FN)/(FN+TP)
 
    f1_score =2*(( precision * recall_score)/( precision + recall_score))
 
    print("Precision value of the model: ",precision)
    print("Accuracy of the model: ",accuracy_model)
    print("Recall value of the model: ",recall_score)
    print("Specificity of the model: ",specificity_value)
    print("False Positive rate of the model: ",False_positive_rate)
    print("False Negative rate of the model: ",False_negative_rate)
    print("f1 score of the model: ",f1_score)
    
# LogisticRegression
from sklearn.linear_model import LogisticRegression

logit= LogisticRegression(class_weight='balanced', max_iter=300, ran-dom_state=0).fit(X_train,Y_train)
target = logit.predict(X_test)
CM_logit = pd.crosstab(Y_test,target)
err_metric(CM_logit)

# Confusion Matrix
from sklearn import metrics

cm = metrics.confusion_matrix(Y_test, target)
print(cm)

```

D先生 ： “今回のデータは**「Bank Loan」**ですか・・・。有名なところ（データベース）では、「Titanic」がありますが・・・。なぜ、これを使うんです？”

![imageJL1-22-4](/2022-10-18-QEUR22_INTRO21/imageJL1-22-4.jpg)

QEU:FOUNDER ： “楽だから・・・(笑)。カテゴリデータがないでしょ？あと、タイタニックに比較すれば欠損値が少ないです。事例紹介ですよ・・・、我々のは・・・。ちょっと、計算結果を紹介しましょうか。”

![imageJL1-22-5](/2022-10-18-QEUR22_INTRO21/imageJL1-22-5.jpg)

D先生 ： “メトリックスは比較には便利ですが、様子がわかりにくいですね。それでは、**CONFUSION_MATRIX**で表現しましょう。”

![imageJL1-22-6](/2022-10-18-QEUR22_INTRO21/imageJL1-22-6.jpg)

QEU:FOUNDER ： “じゃあ、つぎにJulia言語でやってみましょう。プログラムをドン！！”

```julia
# Julia logistic regression
# import necessary packages
using DataFrames
using CSV
using StatsBase
using GLM
using Lathe
using MLBase
using ScikitLearn

# ---
ENV["COLUMNS"] = 1000
df=CSV.read("bank-loan.csv", DataFrame)
first(df,5)

# ---
# To see the variables’ names:
names(df)
#9-element Vector{String}:
# "age"
# "ed"
# "employ"
# "address"
# "income"
# "debtinc"
# "creddebt"
# "othdebt"
# "default"

# ---
# [FIRST]Count classes:
countmap(df.default)
#Dict{Union{Missing, Int64}, Int64} with 3 entries:
#  0       => 517
#  missing => 150
#  1       => 183

# ---
# Check variables’ type:
eltype.(eachcol(df))

# ---
# clearning data:
dropmissing!(df)

# ---
# [SECOND] check classes again:
countmap(df.default)
#Dict{Union{Missing, Int64}, Int64} with 3 entries:
#  0       => 517
#  1       => 183

# ---
# 「テストセット」と「トレーニングセット」に分割する
using Lathe.preprocess: TrainTestSplit
df_train, df_test = TrainTestSplit(df,.8)

# ---
# Create X and Y(train, test)
Y_train = df_train[!, 9]
X_train = Matrix(df_train[!, 1:8])
Y_test  = df_test[!, 9]
X_test  = Matrix(df_test[!, 1:8])

# ---
# [First]train the Logistic Regression Model:
fm = @formula(default ~ age+ed+employ+address+income+debtinc+creddebt+othdebt)
logit = glm(fm, df_train, Binomial(), ProbitLink())
#Coefficients:
#──────────────────────────────────
#                   Coef.  Std. Error      z  Pr(>|z|)    Lower 95%    Upper 95%
#──────────────────────────────────
#(Intercept)  -0.723229    0.403316    -1.79    0.0729  -1.51371      0.0672555
#age           0.0187216   0.0115188    1.63    0.1041  -0.00385481   0.041298
#ed           -0.00137624  0.0780456   -0.02    0.9859  -0.154343     0.15159
#employ       -0.155248    0.0205893   -7.54    <1e-13  -0.195602    -0.114893
#address      -0.0584402   0.0144044   -4.06    <1e-04  -0.0866722   -0.0302081
#income       -0.00483804  0.00520436  -0.93    0.3526  -0.0150384    0.00536231
#debtinc       0.0348257   0.02004      1.74    0.0822  -0.00445197   0.0741034
#creddebt      0.417544    0.0735615    5.68    <1e-07   0.273366     0.561722
#othdebt       0.0289949   0.0526869    0.55    0.5821  -0.0742695    0.132259
#──────────────────────────────────

# ---
# [Second]train the Logistic Regression Model:
fm = @formula(default ~ age+employ+address+debtinc+creddebt)
logit = glm(fm, df_train, Binomial(), ProbitLink())
#Coefficients:
#──────────────────────────────────
#                   Coef.  Std. Error      z  Pr(>|z|)    Lower 95%    Upper 95%
#──────────────────────────────────
#(Intercept)  -0.813489    0.337392    -2.41    0.0159  -1.47477     -0.152212
#age           0.0188471   0.0115048    1.64    0.1014  -0.00370188   0.0413961
#employ       -0.15293     0.0190691   -8.02    <1e-14  -0.190305    -0.115555
#address      -0.0583294   0.0143299   -4.07    <1e-04  -0.0864155   -0.0302433
#income       -0.00286243  0.00394003  -0.73    0.4675  -0.0105847    0.00485988
#debtinc       0.0434063   0.0128506    3.38    0.0007   0.0182196    0.0685931
#creddebt      0.404753    0.068723     5.89    <1e-08   0.270058     0.539447
#──────────────────────────────────

# ---
# Try to predict testing data(prob)
using MLBase: predict 
prediction=predict(logit,df_test)

# ---
# Convert the probability score to class:
# 確率スコアをクラスに変換する
Y_pred = [if x < 0.5 0 else 1 end for x in prediction]

# ---
# データの内容を確認する
prediction_df = DataFrame(y_actual = Y_test, y_predicted = Y_pred, prob_predicted = prediction)

# ---
# CONFUSION MATRIX
@sk_import metrics: (accuracy_score, confusion_matrix)
accuracy_score(Y_test, Y_pred)
confusion_matrix(Y_test, Y_pred)

```

D先生 ： “まずは欠損値を覗いて、入力データのアンバランスを見てみましょう。”

![imageJL1-22-7](/2022-10-18-QEUR22_INTRO21/imageJL1-22-7.jpg)

QEU:FOUNDER ： “**0群と1群の入力データの数量差**が大きすぎます。多分、このままでは正しい情報（分析結果）を得るのは難しいでしょう。何はともあれ、先を急ごう・・・。分析結果をドン！！”

![imageJL1-22-8](/2022-10-18-QEUR22_INTRO21/imageJL1-22-8.jpg)

QEU:FOUNDER ： “あきらかに**統計のR言語**バリの分析結果です。すばらしい・・・。説明変数（X）の刈り取りは自分で工夫してください。次に、予測値と実際値を比較してみましょう。”

![imageJL1-22-9](/2022-10-18-QEUR22_INTRO21/imageJL1-22-9.jpg)

D先生 ： “今回は、リンク関数を変えて確率を出力しています。予測と実際が食い違う場合、確率が0.5あたりにあるわけじゃないんだ・・・。”

QEU:FOUNDER ： “ここら辺は本来はもうちょっと細かく検証しましょう。最後に**メトリックスとCONFUSION_MATRIXを出力して**みましょう。”

![imageJL1-22-10](/2022-10-18-QEUR22_INTRO21/imageJL1-22-10.jpg)

QEU:FOUNDER ： “メトリックスの計算時に警告が出ています。いろいろ原因を調べていますが、いまだに対策がわかりません。とりあえず、自分で調べてください。いやなら、メトリックスを手動で計算して、マクロを使わないでください。”

D先生 ： “混合マトリックスのPython版の結果とJulia版の結果は評価が微妙ですね。これは、ちょっとしたことで結果が変わりそうです。”

QEU:FOUNDER ： “だからロジスティック回帰はこわいんだ・・・。”


## ～　まとめ　～

QEU:FOUNDER ： “天才がこの言葉を語ると、しみじみとくるねぇ・・・。”

![imageJL1-22-11](/2022-10-18-QEUR22_INTRO21/imageJL1-22-11.jpg)

C部長 : “**「高齢者によるイノベーション」に応用**しなければいけないですね。”

QEU:FOUNDER ： “そうそう・・・。彼らは**年金をもらえる**んだから、べつに結果を急ぐ必要がないんだ・・・。普通は60歳になると嘱託になるんだったら、いっそ研究職になってしまえばいいんじゃないか？逆に言うと、自分な時間がない若年層の方がイノベーションに向かないんじゃないかと思っています。”

C部長 : “わけのわからないオッサンがマントラを1000回唱えるイノベーションを開発するかもしれませんが・・・（笑）。”

- **おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」**
- **オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」**
- **オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」**

QEU:FOUNDER ： “再度言います。そんなモン、意味なし。即時却下・・・(笑)。”

