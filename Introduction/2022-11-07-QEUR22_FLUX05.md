---
title: QEUR22_FLUX05:　ディープラーニング(3)～回帰-Pythonの場合 (with MPG)
date: 2022-11-07
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "Keras", "ディープラーニング", "回帰"]
excerpt: PythonとKerasを使った回帰
---

## QEUR22_FLUX05:　ディープラーニング(3)～回帰-Pythonの場合 (with MPG)

## ～　あくまでコードは「ご参考」まで・・・　～

D先生 （設定65歳）： “今度はディープラーニングによる**「回帰(regression)」**にいきましょうか・・・。さて、この番組は**「高齢者によるイノベーション」**です。オッサンの〇ズパワーが猛威を振るった21世紀、果たしてここからの挽回は可能か・・・？”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

### オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」

### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

QEU:FOUNDER （設定65歳） ： “こんなクダラン・セリフを日々垂れ流して、それを管理（）と称したんですよね。**もっとやるべきことがあった**のに、ひたすら下に押し付けるばかりで何もやらなかった。そのツケが、よりによって、今、ドバーッと出てきたわけ・・・。ハァ～・・・、しょうがないので、世界大会で周回遅れを知りながら、ヨボヨボとイノベーションの準備をしましょう・・・。”

[![MOVIE1](http://img.youtube.com/vi/GRBD8xzHm3Q/0.jpg)](http://www.youtube.com/watch?v=GRBD8xzHm3Q "山本太郎の国会質問！参議院・環境委員会 ■大臣所信に対する質疑（2022年11月1日 14：35頃～）")

D先生 ： “オッサンはFOUNDERよりもはるかに優秀ですよ。ここは大船に乗ってください、ハッハッ・・・。**あれだけの大口をたたいていた**んですよ。J国経済を立て直すだけの実力がありますって・・・。イケメン（↑）が提唱したように、地道に技術開発を続ければ危機をチャンスに変えることができます。それをあえてやらなかったのが平成だし・・・。”

QEU:FOUNDER ： “あの頃、全員が**「極端に短期的な視野」**になったんだよね・・・。例によって、能書きにアホらしくなったので本題に入りましょう。今回は、「回帰(regression)」問題におけるPython解法の例を紹介しましょう。今回の先生は「オフィシャル」のコレ（↓）！！”

![imageJL1-65-1](/2022-11-07-QEUR22_FLUX05/imageJL1-65-1.jpg)

D先生 ： “なんと！？オフィシャル文献じゃないですか・・・。じゃあ、これで説明はおわりですね。晩御飯を食べに行きましょう・・・。”

QEU:FOUNDER ： “ちょっと待って・・・（汗）。ちょっと追加で説明することがあるんで・・・。”

![imageJL1-65-2](/2022-11-07-QEUR22_FLUX05/imageJL1-65-2.jpg)

D先生 ： “えっ？（説明することは）あるの？”

![imageJL1-65-3](/2022-11-07-QEUR22_FLUX05/imageJL1-65-3.jpg)

QEU:FOUNDER ： “パッケージのシステム開発が頻繁なので、オフィシャルで紹介されたコードでは動かない可能性もあります。だから、二番煎じでも、それなりの価値があります。あとは、コードのこの部分（↑）に注意するように提起したいです。”

D先生 ： “このコードになんかあるんですか？”

QEU:FOUNDER ： “このCSVファイルの読み込み命令は**「凝っている」**から、特に気を付けて・・・。命令の**オプションの詳細は自分で調べて**ね。”

D先生 ： “あんまり、意味のない説明だなぁ・・・。”

QEU:FOUNDER ： “あとはPYTHONプログラムをドン！”

```python
# python_auto_MPG
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
tf.random.set_seed(42)
from tensorflow import keras

column_names = ["MPG", "Cylinders", "Displacement", "Horsepower", "Weight",
                "Acceleration", "Model Year", "Origin"]
df = pd.read_csv("auto-mpg.data", names=column_names, sep=" ",
                 comment="\t", na_values="?", skipinitialspace=True)
df.head()

```

![imageJL1-65-4](/2022-11-07-QEUR22_FLUX05/imageJL1-65-4.jpg)

```python
# ----
df.isna().sum()

```

![imageJL1-65-5](/2022-11-07-QEUR22_FLUX05/imageJL1-65-5.jpg)

```python
# ----
df = df.dropna()
df.isna().sum()

```

![imageJL1-65-6](/2022-11-07-QEUR22_FLUX05/imageJL1-65-6.jpg)

```python
# ----
origin = df.pop('Origin')
df['USA'] = (origin == 1) * 1.0
df['Europe'] = (origin == 2) * 1.0
df['Japan'] = (origin == 3) * 1.0
df

```

![imageJL1-65-7](/2022-11-07-QEUR22_FLUX05/imageJL1-65-7.jpg)

```python
# ----
# CSVファイルの出力
df.to_csv('auto-mpg-processed-data.csv')

```

D先生 ： “いきなり、CSVファイルに出力していますね”

QEU:FOUNDER ： “つぎのブログではJulia言語で予測できるかどうかをやってみます。さすがに、あの芸術的なCSVファイル命令をJulia言語で再現したくないんで・・・。”

D先生 ： “無理なことをしたくない気持ちは大いに同意します・・・(笑)。”

```python
# ----
# train - test
train_df = df.sample(frac=0.8, random_state=0)
test_df = df.drop(train_df.index)
train_df

# ----
import seaborn as sns

sns.pairplot(train_df[['MPG', 'Cylinders', 'Displacement', 'Weight']], diag_kind='kde')
train_df.describe().transpose()

# ----
# ラベルと特徴量の分離
train_features = train_df.copy()
test_features = test_df.copy()

train_labels = train_features.pop('MPG')
test_labels = test_features.pop('MPG')

# ----
# 正規化（mean, std）
train_df.describe().transpose()[['mean', 'std']]

# ----
# レイヤーの正規化
normalizer = tf.keras.layers.Normalization(axis=-1)
normalizer.adapt(np.array(train_features))
print(normalizer.mean.numpy())

```

![imageJL1-65-8](/2022-11-07-QEUR22_FLUX05/imageJL1-65-8.jpg)

```python
# ----
first = np.array(train_features[:1])

with np.printoptions(precision=2, suppress=True):
  print('First example:', first)
  print()
  print('Normalized:', normalizer(first).numpy())

```

![imageJL1-65-9](/2022-11-07-QEUR22_FLUX05/imageJL1-65-9.jpg)

```python
# ----
# 一次近似の場合
# 馬力 Normalization レイヤーを作成します
horsepower = np.array(train_features['Horsepower'])
horsepower_normalizer = tf.keras.layers.Normalization(input_shape=[1,], axis=None)
horsepower_normalizer.adapt(horsepower)

# Sequential モデルを作成します
horsepower_model = tf.keras.Sequential([
    horsepower_normalizer,
    tf.keras.layers.Dense(units=1)
])

horsepower_model.summary()

```

![imageJL1-65-10](/2022-11-07-QEUR22_FLUX05/imageJL1-65-10.jpg)

```python
# ----
# Horsepower から MPG を予測します。
horsepower_model.predict(horsepower[:10])

```

![imageJL1-65-11](/2022-11-07-QEUR22_FLUX05/imageJL1-65-11.jpg)

```python
# ----
# モデルのコンパイル
horsepower_model.compile(
    optimizer=tf.optimizers.Adam(learning_rate=0.1),
    loss='mean_absolute_error')

%%time  # located at the top of cell
# ----
# トレーニングを実行します。
history = horsepower_model.fit(
    train_features['Horsepower'],
    train_labels,
    epochs=100,
    # Suppress logging.
    verbose=0,
    # Calculate validation results on 20% of the training data.
    validation_split = 0.2)

# ----
# モデルのトレーニングの様子を可視化します(1)
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

```

![imageJL1-65-12](/2022-11-07-QEUR22_FLUX05/imageJL1-65-12.jpg)

```python
# ----
# モデルのトレーニングの様子を可視化します(2)
def plot_loss(history):
  plt.plot(history.history['loss'], label='loss')
  plt.plot(history.history['val_loss'], label='val_loss')
  plt.ylim([0, 30])
  plt.xlabel('Epoch')
  plt.ylabel('Error [MPG]')
  plt.legend()
  plt.grid(True)

plot_loss(history)

```

![imageJL1-65-13](/2022-11-07-QEUR22_FLUX05/imageJL1-65-13.jpg)

```python
# ----
# テスト用セットの結果を収集します。
test_results = {}

test_results['horsepower_model'] = horsepower_model.evaluate(
    test_features['Horsepower'],
    test_labels, verbose=0)
test_results

# ----
# 入力の関数としてモデルの予測を簡単に確認できます。
x = tf.linspace(0.0, 250, 251)
y = horsepower_model.predict(x)

def plot_horsepower(x, y):
  plt.scatter(train_features['Horsepower'], train_labels, label='Data')
  plt.plot(x, y, color='k', label='Predictions')
  plt.xlabel('Horsepower')
  plt.ylabel('MPG')
  plt.legend()

plot_horsepower(x, y)

```

![imageJL1-65-14](/2022-11-07-QEUR22_FLUX05/imageJL1-65-14.jpg)

```python
# ----
# DNN 回帰
def build_and_compile_model(norm):
  model = keras.Sequential([
      norm,
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(1)
  ])

  model.compile(loss='mean_absolute_error',
                optimizer=tf.keras.optimizers.Adam(0.001))
  return model

# ----
# DNN完全モデル
dnn_model = build_and_compile_model(normalizer)
dnn_model.summary()

```

![imageJL1-65-15](/2022-11-07-QEUR22_FLUX05/imageJL1-65-15.jpg)

```python
%%time
# ----
# モデルをトレーニングします。
history = dnn_model.fit(
    train_features,
    train_labels,
    validation_split=0.2,
    verbose=0, epochs=100)

# 結果の可視化
plot_loss(history)

```

![imageJL1-65-16](/2022-11-07-QEUR22_FLUX05/imageJL1-65-16.jpg)

```python
# ----
# テスト用セットの結果を収集します。
test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)
test_results

# ----
# テスト用セットの性能を確認します。
pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T

# ----
# モデルを使った予測
test_predictions = dnn_model.predict(test_features).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_labels, test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
lims = [0, 50]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims, lims)

```

![imageJL1-65-17](/2022-11-07-QEUR22_FLUX05/imageJL1-65-17.jpg)

D先生 ： “さすがに、オフィシャルのやり方は美しいですね。この出来では、FOUNDERもとくにコメントはないでしょう？”

QEU:FOUNDER ： “次回のJulia言語につづく・・・。”


## ～　まとめ　～

### ・・・　本来ならば、「ある団体の件」の完結ですが　・・・

C部長 : “FOUNDER、**速報**です！”

QEU:FOUNDER ： “いきなり、なんですか・・・？”

![imageJL1-65-18](/2022-11-07-QEUR22_FLUX05/imageJL1-65-18.jpg)

QEU:FOUNDER ： “この人、誰・・・？”

C部長 : “知らないんですか？”

![imageJL1-65-19](/2022-11-07-QEUR22_FLUX05/imageJL1-65-19.jpg)

QEU:FOUNDER ： “この人たちが出演しているんですか・・・？”

C部長 : “多分、違うと思います。”

QEU:FOUNDER ： “どっちみち、見ないけどさ・・・。”


